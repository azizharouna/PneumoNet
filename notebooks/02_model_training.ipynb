{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Y1NNg_JDbrszcqQj-2N7aCGsCzrZI3xq","authorship_tag":"ABX9TyN6bZiYZPjG6K430J5bDfM3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 02_model_training.ipynb\n","\n","This notebook trains a Convolutional Neural Network (CNN) to detect pneumonia from chest X-ray images using PyTorch. It loads preprocessed data from a saved `.npz` file, defines the model architecture, and trains the model.\n","\n"],"metadata":{"id":"lu9WSbsWkji_"}},{"cell_type":"code","source":["## Imports and Setup\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import numpy as np\n","import os\n","\n","# Check if GPU is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"],"metadata":{"id":"yA8E8a6ok_mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLuLqTLfxrzK","executionInfo":{"status":"ok","timestamp":1724219825277,"user_tz":-120,"elapsed":6,"user":{"displayName":"Abdoul Aziz Moussa","userId":"00107072618696679670"}},"outputId":"943ece82-94bc-44ed-e3bf-91303ccb28d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWA5UQzwfr5p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724219851709,"user_tz":-120,"elapsed":25801,"user":{"displayName":"Abdoul Aziz Moussa","userId":"00107072618696679670"}},"outputId":"d108c3e2-cb81-4d6a-9ab3-2878bef98b77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (4172, 150, 150, 3), Labels: 4172\n","Testing set: (624, 150, 150, 3), Labels: 624\n","Validation set: (1060, 150, 150, 3), Labels: 1060\n"]}],"source":["# Define the path to the processed data directory\n","processed_data_dir = '/content/drive/MyDrive/projects/data/processed'\n","\n","# Define the path for the .npz file\n","data_file_path = os.path.join(processed_data_dir, 'data.npz')\n","\n","# Load the data\n","data = np.load(data_file_path)\n","\n","train_images = data['train_images']\n","train_labels = data['train_labels']\n","test_images = data['test_images']\n","test_labels = data['test_labels']\n","val_images = data['val_images']\n","val_labels = data['val_labels']\n","\n","# Display shapes\n","print(f\"Training set: {train_images.shape}, Labels: {len(train_labels)}\")\n","print(f\"Testing set: {test_images.shape}, Labels: {len(test_labels)}\")\n","print(f\"Validation set: {val_images.shape}, Labels: {len(val_labels)}\")\n"]},{"cell_type":"code","source":["from torchvision import transforms\n","from PIL import Image\n","class PneumoniaDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","        # Convert labels from strings to integers\n","        label_mapping = {'NORMAL': 0, 'PNEUMONIA': 1}\n","        self.labels = np.array([label_mapping[label] for label in labels])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx].astype(np.uint8)  # Ensure uint8 format\n","        image = Image.fromarray(image)  # Convert numpy array to PIL Image\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)  # Apply transformations\n","        return image, torch.tensor(label, dtype=torch.long)  # Convert label to tensor\n","\n","\n","\n","\n","transform = transforms.Compose([\n","    transforms.Resize((150, 150)),  # Resize to the target size\n","    transforms.ToTensor(),          # Convert to tensor\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n","])\n","\n","\n","# Convert numpy arrays to PyTorch DataLoader\n","def preprocess_data(images, labels, transform=None):\n","    dataset = PneumoniaDataset(images, labels, transform)\n","    return DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","train_loader = preprocess_data(train_images, train_labels, transform)\n","val_loader = preprocess_data(val_images, val_labels, transform)\n","test_loader = preprocess_data(test_images, test_labels, transform)\n"],"metadata":{"id":"gYWBCiuZlXsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm import tqdm  # Importing tqdm for progress bars\n","\n","def train_model(model, train_loader, val_loader, num_epochs=10):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)  # Move model to the appropriate device\n","\n","    criterion = nn.CrossEntropyLoss()  # Define loss function\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Define optimizer\n","\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","        running_loss = 0.0\n","\n","        # Add tqdm to training loop\n","        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n","\n","        for images, labels in train_loader_tqdm:\n","            images, labels = images.to(device), labels.to(device)  # Move tensors to the device\n","\n","            optimizer.zero_grad()  # Zero the parameter gradients\n","            outputs = model(images)  # Forward pass\n","            loss = criterion(outputs, labels)  # Compute loss\n","            loss.backward()  # Backward pass\n","            optimizer.step()  # Update model parameters\n","\n","            running_loss += loss.item()\n","\n","            # Optionally, update tqdm with current loss for the batch\n","            train_loader_tqdm.set_postfix(loss=loss.item())\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n","\n","        # Validation phase\n","        model.eval()  # Set model to evaluation mode\n","        val_loss = 0.0\n","        correct_predictions = 0\n","        total_samples = 0\n","\n","        # Add tqdm to validation loop\n","        val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n","\n","        with torch.no_grad():\n","            for images, labels in val_loader_tqdm:\n","                images, labels = images.to(device), labels.to(device)  # Move tensors to the device\n","                outputs = model(images)  # Forward pass\n","                loss = criterion(outputs, labels)  # Compute loss\n","                val_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                total_samples += labels.size(0)\n","                correct_predictions += (predicted == labels).sum().item()\n","\n","                # Optionally, update tqdm with current validation loss\n","                val_loader_tqdm.set_postfix(loss=loss.item())\n","\n","        val_loss = val_loss / len(val_loader)\n","        accuracy = 100 * correct_predictions / total_samples\n","        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n","\n","    print(\"Training complete\")"],"metadata":{"id":"y_qn359CldmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class PneumoniaNet(nn.Module):\n","    def __init__(self):\n","        super(PneumoniaNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","        # Calculate the input size for fc1 dynamically\n","        self._calculate_fc1_input_size()\n","\n","        self.fc1 = nn.Linear(self.fc1_input_size, 512)  # Use calculated input size for fc1\n","        self.fc2 = nn.Linear(512, 2)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def _calculate_fc1_input_size(self):\n","        # Pass a dummy input through the network to compute the size before the fully connected layers\n","        dummy_input = torch.zeros(1, 3, 150, 150)  # Batch size 1, 3 channels, 150x150 image\n","        x = self.pool(F.relu(self.conv1(dummy_input)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        self.fc1_input_size = x.view(1, -1).size(1)  # Flatten the tensor and get its size\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","\n","        # Flatten the tensor\n","        x = x.view(x.size(0), -1)  # Dynamically flatten the tensor\n","\n","        x = self.dropout(F.relu(self.fc1(x)))\n","        x = self.fc2(x)\n","        return x\n","\n","# Instantiate the model and move it to the appropriate device\n","model = PneumoniaNet()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","# train_model function\n","train_model(model, train_loader, val_loader, num_epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7R6UFGBumSyf","executionInfo":{"status":"ok","timestamp":1724223336185,"user_tz":-120,"elapsed":3484499,"user":{"displayName":"Abdoul Aziz Moussa","userId":"00107072618696679670"}},"outputId":"119b0724-cfc0-4811-f44d-57be9bc34689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.6145\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5742, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [2/10], Loss: 0.5759\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5811, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [3/10], Loss: 0.5757\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5684, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [4/10], Loss: 0.5734\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.6665, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [5/10], Loss: 0.5751\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5898, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [6/10], Loss: 0.5736\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5747, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [7/10], Loss: 0.5719\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5809, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [8/10], Loss: 0.5731\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5688, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [9/10], Loss: 0.5746\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5810, Accuracy: 73.87%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Loss: 0.5746\n"]},{"output_type":"stream","name":"stderr","text":["                                                                       "]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5676, Accuracy: 73.87%\n","Training complete\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]}]}